# Практическая работа по интеллектуальному анализу данных №5-6. Кластеризация данных.

## Часть 1. Очистка данных.

### Задание 1. Восстановление пропущенных данных.

Функция удаления определённого процента элементов из списка


```python
import random

def remove(n, lst):
    [lst.pop(i) for i in sorted(random.sample(range(len(lst)), k=int(len(lst)*n)),
                                reverse=True)]
    return lst 
```


```python
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import mean_squared_error

def approximation(poly_power):
  x_list = [i * 0.05 for i in range(201)]
  x = remove(0.5, x_list[:])
  x_removed = []
  for i in x_list:
    if i not in x:
      x_removed.append(i)
  y = np.sin(x)
  t = np.polyfit(x, y, poly_power)
  f = np.poly1d(t)

  print("Степень аппроксимируещей функции:", poly_power)
  print(f)
  print("MSE =", mean_squared_error(np.sin(x_removed), f(x_removed)))
  plt.grid()
  plt.plot(x_removed, f(x_removed), 'o', x, y, 'ro', )
  plt.show()
```


```python
approximation(4)
approximation(5)
approximation(6)
approximation(7)
```

    Степень аппроксимируещей функции: 4
              4          3         2
    -0.01147 x + 0.2184 x - 1.274 x + 2.24 x - 0.193
    MSE = 0.05525277911877309
    


![](https://i.imgur.com/9MTzxqN.png)



    Степень аппроксимируещей функции: 5
               5           4        3         2
    0.0009911 x - 0.03614 x + 0.44 x - 2.134 x + 3.56 x - 0.7076
    MSE = 0.03338430805546465
    


![](https://i.imgur.com/ckl7O1I.png)



    Степень аппроксимируещей функции: 6
               6           5          4          3          2
    0.0005657 x - 0.01613 x + 0.1605 x - 0.6247 x + 0.5917 x + 0.7112 x + 0.02893
    MSE = 0.0012077729396210838
    


![](https://i.imgur.com/bOeZc0a.png)



    Степень аппроксимируещей функции: 7
                7            6           5          4          3          2
    -2.159e-05 x + 0.001294 x - 0.02578 x + 0.2238 x - 0.8375 x + 0.9355 x + 0.4944 x + 0.05537
    MSE = 0.0005995019552604662
    


![](https://i.imgur.com/WtBG8xA.png)

Заметим, что чем выше степнь аппроксимирующей функции, тем точнее восстановление зависимости.

### Задание 2. Редактирование аномалий. 


```python
import pandas as pd

anketa = pd.read_csv("/content/sample_data/Anketa.txt", encoding='Windows 1251', delimiter='\t')
anketa.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Фамилия</th>
      <th>Имя</th>
      <th>Отчество</th>
      <th>КодАнкеты</th>
      <th>Сумма кредита, руб#</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Абаджев</td>
      <td>Николай</td>
      <td>Васильевич</td>
      <td>3049</td>
      <td>47000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Абаев</td>
      <td>Александр</td>
      <td>Викторович</td>
      <td>3061</td>
      <td>32000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Алексенко</td>
      <td>Дмитрий</td>
      <td>Дмитриевич</td>
      <td>4012</td>
      <td>64000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Беляев</td>
      <td>Юрий</td>
      <td>Алефтинович</td>
      <td>3053</td>
      <td>25000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Бобров</td>
      <td>Андрей</td>
      <td>Владимирович</td>
      <td>4076</td>
      <td>105000</td>
    </tr>
  </tbody>
</table>
</div>




```python
anketa['Сумма кредита, руб#'].plot(kind='box')
plt.show()
```


![](https://i.imgur.com/E5v6rx8.png)



Как мы видим из диаграммы "ящика с усами" в данных присутствуют чересчур высокие суммы кредита, возможно это аномалии.


```python
anketa['Сумма кредита, руб#'].plot(kind='hist')
plt.show()
```


![](https://i.imgur.com/F3c6I6J.png)



Гистограмма помогла определить нам примерное количество аномальных значений. Теперь мы можем отредактировать эти значения и присвоить им, например, среднее или медианное значение, либо можем удалить строки.


```python
median = anketa['Сумма кредита, руб#'].median()
print("Медианное значение: ", median)
```

    Медианное значение:  47000.0
    

Выведем строки с аномальными значениеми.


```python
anomalies = anketa.loc[anketa['Сумма кредита, руб#'] > 100000]
anomalies
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Фамилия</th>
      <th>Имя</th>
      <th>Отчество</th>
      <th>КодАнкеты</th>
      <th>Сумма кредита, руб#</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4</th>
      <td>Бобров</td>
      <td>Андрей</td>
      <td>Владимирович</td>
      <td>4076</td>
      <td>105000</td>
    </tr>
    <tr>
      <th>41</th>
      <td>Лаврентьева</td>
      <td>Юлия</td>
      <td>Никифоровна</td>
      <td>4060</td>
      <td>140000</td>
    </tr>
    <tr>
      <th>75</th>
      <td>Ханнаков</td>
      <td>Медахат</td>
      <td>Рифкатович</td>
      <td>4013</td>
      <td>120000</td>
    </tr>
    <tr>
      <th>83</th>
      <td>Бобров</td>
      <td>Андрей</td>
      <td>Владимирович</td>
      <td>4076</td>
      <td>105000</td>
    </tr>
  </tbody>
</table>
</div>



Удалим эти строки, а также все строки-дубликаты.


```python
anketa = anketa.drop_duplicates()
anketa.loc[anketa['Сумма кредита, руб#'] > 100000, 'Сумма кредита, руб#'] = median
anketa
```

В итоге поличим данные без дубликатов и аномальнх значений. Теперь эти данные лучше подходят для дальнейшего анализа.


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Фамилия</th>
      <th>Имя</th>
      <th>Отчество</th>
      <th>КодАнкеты</th>
      <th>Сумма кредита, руб#</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Абаджев</td>
      <td>Николай</td>
      <td>Васильевич</td>
      <td>3049</td>
      <td>47000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Абаев</td>
      <td>Александр</td>
      <td>Викторович</td>
      <td>3061</td>
      <td>32000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Алексенко</td>
      <td>Дмитрий</td>
      <td>Дмитриевич</td>
      <td>4012</td>
      <td>64000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Беляев</td>
      <td>Юрий</td>
      <td>Алефтинович</td>
      <td>3053</td>
      <td>25000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Бобров</td>
      <td>Андрей</td>
      <td>Владимирович</td>
      <td>4076</td>
      <td>47000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>78</th>
      <td>Чекина</td>
      <td>Ольга</td>
      <td>Сергеевна</td>
      <td>4082</td>
      <td>45000</td>
    </tr>
    <tr>
      <th>79</th>
      <td>Чешкова</td>
      <td>Елена</td>
      <td>Борисовна</td>
      <td>4005</td>
      <td>41000</td>
    </tr>
    <tr>
      <th>80</th>
      <td>Широкова</td>
      <td>Светлана</td>
      <td>Николаевна</td>
      <td>4000</td>
      <td>54000</td>
    </tr>
    <tr>
      <th>81</th>
      <td>Шуклин</td>
      <td>Виталий</td>
      <td>Георгиевич</td>
      <td>3067</td>
      <td>36000</td>
    </tr>
    <tr>
      <th>82</th>
      <td>Якуб</td>
      <td>Андрей</td>
      <td>Сергеевич</td>
      <td>4077</td>
      <td>17000</td>
    </tr>
  </tbody>
</table>
<p>83 rows × 5 columns</p>
</div>



### Задание 3. Сглаживание и очистка от шумов.

Просмотрим данные, которые содержатся в таблице:


```python
dynamics_website = pd.read_csv("/content/sample_data/dynamics_website.txt", encoding='Windows 1251', delimiter='\t')
dynamics_website.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Дата</th>
      <th>Посещения</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>01.01.2009</td>
      <td>163,654</td>
    </tr>
    <tr>
      <th>1</th>
      <td>01.12.2008</td>
      <td>180,472</td>
    </tr>
    <tr>
      <th>2</th>
      <td>01.11.2008</td>
      <td>184,68</td>
    </tr>
    <tr>
      <th>3</th>
      <td>01.10.2008</td>
      <td>190,564</td>
    </tr>
    <tr>
      <th>4</th>
      <td>01.09.2008</td>
      <td>164,578</td>
    </tr>
  </tbody>
</table>
</div>


Прийдётс провести некоторые преобразования для дальнейшей работы с ними. В частности, приведём данные к числовому типу.

```python
for index, row in dynamics_website.iterrows():
  s = row['Посещения'].replace(',', '.')
  s2= row['Дата'][3:].replace('.', '-')
  dynamics_website.loc[dynamics_website['Посещения'] == row['Посещения'], 'Посещения'] = s
  dynamics_website.loc[dynamics_website['Дата'] == row['Дата'], 'Дата'] = s2

dynamics_website['Дата'] = dynamics_website['Дата'].astype('datetime64')
dynamics_website['Посещения'] = dynamics_website['Посещения'].astype('float64')
```
Функция отрисовки графика:

```python
def plot_dynamics():
  fig, ax = plt.subplots()
  ax.plot(dynamics_website['Дата'], dynamics_website['Посещения'])
  ax.xaxis_date()
  fig.autofmt_xdate()
  plt.show()
```


```python
plot_dynamics()
```


![](https://i.imgur.com/c3ZA9gC.png)


Теперь попробуем провести сглаживание и очистку от шумов. В данной работе я использовал функцию простого экспоненциального сглаживания по модели Хольта-Винтерса:

$$\hat{y}_{t} = \alpha \cdot y_t + (1-\alpha) \cdot \hat y_{t-1}$$

Возьмём
$$\alpha=0,5$$

```python
def exponential_smoothing(series, alpha):
    result = [series[0]]
    for n in range(1, len(series)):
        result.append(alpha * series[n] + (1 - alpha) * result[n-1])
    return result
```

Тепрь проведём сглаживание и очистку. И изобразим график.

```python
dynamics_website['Посещения'] = exponential_smoothing(dynamics_website['Посещения'], 0.5)
plot_dynamics()
```


![](https://i.imgur.com/JNmEGs1.png)

Как мы можем заметить, после сглаживания график стал более плавным, без слишком резких перепадов.



## Часть 2. Кластеризация данных.

### Задание 1. Кластеризация государств мира.

Для данного задания были взяты датасеты с сайта Kaggle.com. Первый датасет - [Population by Country - 2020](https://www.kaggle.com/tanuprabhu/population-by-country-2020). Второй - [Country Statistics - UNData](https://www.kaggle.com/sudalairajkumar/undata-country-profiles).

```python
import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import os
import matplotlib.pyplot as plt
```
Импортируем данные, удалим пропуски, посмотрим содержание таблицы.

```python
population = pd.read_csv("../input/population-by-country-2020/population_by_country_2020.csv")
population.info()
population.loc[population['Country (or dependency)'] == "United States", 'Country (or dependency)'] = "United States of America"
population.loc[population['Country (or dependency)'] == "Russia", 'Country (or dependency)'] = "Russian Federation"
population2 = pd.read_csv("../input/undata-country-profiles/country_profile_variables.csv")
population = population.merge(population2, left_on="Country (or dependency)", right_on="country", how="inner")
population = population.dropna()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 235 entries, 0 to 234
    Data columns (total 11 columns):
     #   Column                   Non-Null Count  Dtype  
    ---  ------                   --------------  -----  
     0   Country (or dependency)  235 non-null    object 
     1   Population (2020)        235 non-null    int64  
     2   Yearly Change            235 non-null    object 
     3   Net Change               235 non-null    int64  
     4   Density (P/Km²)          235 non-null    int64  
     5   Land Area (Km²)          235 non-null    int64  
     6   Migrants (net)           201 non-null    float64
     7   Fert. Rate               235 non-null    object 
     8   Med. Age                 235 non-null    object 
     9   Urban Pop %              235 non-null    object 
     10  World Share              235 non-null    object 
    dtypes: float64(1), int64(4), object(6)
    memory usage: 20.3+ KB


```python
population = population[['Country (or dependency)', 'Population (2020)', 'Urban population (% of total population)', 
                         'Yearly Change', 'Unemployment (% of labour force)', 'GDP per capita (current US$)']]
population
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country (or dependency)</th>
      <th>Population (2020)</th>
      <th>Urban population (% of total population)</th>
      <th>Yearly Change</th>
      <th>Unemployment (% of labour force)</th>
      <th>GDP per capita (current US$)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>China</td>
      <td>1440297825</td>
      <td>55.6</td>
      <td>0.39 %</td>
      <td>4.6</td>
      <td>8109.1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>India</td>
      <td>1382345085</td>
      <td>32.7</td>
      <td>0.99 %</td>
      <td>3.4</td>
      <td>1614.2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>United States of America</td>
      <td>331341050</td>
      <td>81.6</td>
      <td>0.59 %</td>
      <td>4.9</td>
      <td>56053.8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Indonesia</td>
      <td>274021604</td>
      <td>53.7</td>
      <td>1.07 %</td>
      <td>5.8</td>
      <td>3346.5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Pakistan</td>
      <td>221612785</td>
      <td>38.8</td>
      <td>2.00 %</td>
      <td>5.9</td>
      <td>1410.4</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>171</th>
      <td>Grenada</td>
      <td>112614</td>
      <td>35.6</td>
      <td>0.46 %</td>
      <td>...</td>
      <td>8933.8</td>
    </tr>
    <tr>
      <th>172</th>
      <td>Aruba</td>
      <td>106845</td>
      <td>41.5</td>
      <td>0.43 %</td>
      <td>...</td>
      <td>26005.4</td>
    </tr>
    <tr>
      <th>173</th>
      <td>Tonga</td>
      <td>105901</td>
      <td>23.7</td>
      <td>1.15 %</td>
      <td>4.8</td>
      <td>3784.5</td>
    </tr>
    <tr>
      <th>174</th>
      <td>Seychelles</td>
      <td>98453</td>
      <td>53.9</td>
      <td>0.62 %</td>
      <td>4.1</td>
      <td>14133.2</td>
    </tr>
    <tr>
      <th>175</th>
      <td>Antigua and Barbuda</td>
      <td>98069</td>
      <td>23.8</td>
      <td>0.84 %</td>
      <td>...</td>
      <td>14764.5</td>
    </tr>
  </tbody>
</table>
<p>176 rows × 6 columns</p>
</div>


Приведём данные к необходимому для обработки типу.

```python
population = population.drop(np.where(population['Unemployment (% of labour force)'] == '...')[0])
population['Unemployment (% of labour force)'] = population['Unemployment (% of labour force)'].astype('float64')
for index, row in population.iterrows():
  s = row['Yearly Change'].replace(' %', '')
  population.loc[population['Yearly Change'] == row['Yearly Change'], 'Yearly Change'] = s
population['Yearly Change'] = population['Yearly Change'].astype('float64')
population
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country (or dependency)</th>
      <th>Population (2020)</th>
      <th>Urban population (% of total population)</th>
      <th>Yearly Change</th>
      <th>Unemployment (% of labour force)</th>
      <th>GDP per capita (current US$)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>China</td>
      <td>1440297825</td>
      <td>55.6</td>
      <td>0.39</td>
      <td>4.6</td>
      <td>8109.1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>India</td>
      <td>1382345085</td>
      <td>32.7</td>
      <td>0.99</td>
      <td>3.4</td>
      <td>1614.2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>United States of America</td>
      <td>331341050</td>
      <td>81.6</td>
      <td>0.59</td>
      <td>4.9</td>
      <td>56053.8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Indonesia</td>
      <td>274021604</td>
      <td>53.7</td>
      <td>1.07</td>
      <td>5.8</td>
      <td>3346.5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Pakistan</td>
      <td>221612785</td>
      <td>38.8</td>
      <td>2.00</td>
      <td>5.9</td>
      <td>1410.4</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>167</th>
      <td>Saint Lucia</td>
      <td>183774</td>
      <td>18.5</td>
      <td>0.46</td>
      <td>19.0</td>
      <td>7839.4</td>
    </tr>
    <tr>
      <th>168</th>
      <td>Channel Islands</td>
      <td>174140</td>
      <td>31.5</td>
      <td>0.93</td>
      <td>8.7</td>
      <td>-99.0</td>
    </tr>
    <tr>
      <th>169</th>
      <td>Guam</td>
      <td>169031</td>
      <td>94.5</td>
      <td>0.89</td>
      <td>10.7</td>
      <td>-99.0</td>
    </tr>
    <tr>
      <th>173</th>
      <td>Tonga</td>
      <td>105901</td>
      <td>23.7</td>
      <td>1.15</td>
      <td>4.8</td>
      <td>3784.5</td>
    </tr>
    <tr>
      <th>174</th>
      <td>Seychelles</td>
      <td>98453</td>
      <td>53.9</td>
      <td>0.62</td>
      <td>4.1</td>
      <td>14133.2</td>
    </tr>
  </tbody>
</table>
<p>171 rows × 6 columns</p>
</div>


Оставим только 50 стран с самой большой численностью населения. Проверим правильность преобразования типов.

```python
population = population.head(50)
population.info()
```

    <class 'pandas.core.frame.DataFrame'>
    Int64Index: 50 entries, 0 to 49
    Data columns (total 6 columns):
     #   Column                                    Non-Null Count  Dtype  
    ---  ------                                    --------------  -----  
     0   Country (or dependency)                   50 non-null     object 
     1   Population (2020)                         50 non-null     int64  
     2   Urban population (% of total population)  50 non-null     float64
     3   Yearly Change                             50 non-null     float64
     4   Unemployment (% of labour force)          50 non-null     float64
     5   GDP per capita (current US$)              50 non-null     float64
    dtypes: float64(4), int64(1), object(1)
    memory usage: 2.7+ KB
    
Проведём шкалирование данных и обозначим равенство каждого параметра для дальнейшей кластеризации.

```python
X = population.loc[:, ['Population (2020)', 'Urban population (% of total population)', 
                       'Yearly Change', 'Unemployment (% of labour force)', 'GDP per capita (current US$)']]
scaler = StandardScaler()
scaler.fit(X)
X = scaler.transform(X)
X = pd.DataFrame(X)
X.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4.847088</td>
      <td>0.002085</td>
      <td>-0.970201</td>
      <td>-0.574123</td>
      <td>-0.184091</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.632669</td>
      <td>-0.992539</td>
      <td>-0.394072</td>
      <td>-0.800008</td>
      <td>-0.619479</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.744066</td>
      <td>1.131352</td>
      <td>-0.778158</td>
      <td>-0.517652</td>
      <td>3.029896</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.531990</td>
      <td>-0.080439</td>
      <td>-0.317255</td>
      <td>-0.348239</td>
      <td>-0.503354</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.338083</td>
      <td>-0.727596</td>
      <td>0.575745</td>
      <td>-0.329415</td>
      <td>-0.633141</td>
    </tr>
  </tbody>
</table>
</div>


Кластеризируем данные с помощью алгоритма k-средних, а затем изобразим на диаграмме каждый кластер отдельным цветом.


```python
kmeans = KMeans(n_clusters=5)
X["Cluster"] = kmeans.fit_predict(X)
X["Cluster"] = X["Cluster"].astype("category")
X.rename(columns={0: 'численность населения', 1: 'урбанизация', 2: 'годовое изменение численности', 
                  3: 'безработица', 4: 'ВВП на душу населения'}, inplace=True)
X.head()

sns.pairplot(X, hue="Cluster")
```






![](https://i.imgur.com/l2w6yl1.png)


Теперь разберёмся, какие государства к какому кластеру относятся.

```python
a = pd.DataFrame({'Государство': list(population['Country (or dependency)']), 'Кластер': X['Cluster']})
a.sort_values(by='Кластер')
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Государство</th>
      <th>Кластер</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>26</th>
      <td>Argentina</td>
      <td>0</td>
    </tr>
    <tr>
      <th>23</th>
      <td>Colombia</td>
      <td>0</td>
    </tr>
    <tr>
      <th>29</th>
      <td>Ukraine</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Indonesia</td>
      <td>0</td>
    </tr>
    <tr>
      <th>32</th>
      <td>Poland</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Brazil</td>
      <td>0</td>
    </tr>
    <tr>
      <th>34</th>
      <td>Morocco</td>
      <td>0</td>
    </tr>
    <tr>
      <th>35</th>
      <td>Saudi Arabia</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Russian Federation</td>
      <td>0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Mexico</td>
      <td>0</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Thailand</td>
      <td>0</td>
    </tr>
    <tr>
      <th>39</th>
      <td>Malaysia</td>
      <td>0</td>
    </tr>
    <tr>
      <th>27</th>
      <td>Algeria</td>
      <td>0</td>
    </tr>
    <tr>
      <th>37</th>
      <td>Peru</td>
      <td>0</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Turkey</td>
      <td>0</td>
    </tr>
    <tr>
      <th>0</th>
      <td>China</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>India</td>
      <td>1</td>
    </tr>
    <tr>
      <th>41</th>
      <td>Ghana</td>
      <td>2</td>
    </tr>
    <tr>
      <th>43</th>
      <td>Nepal</td>
      <td>2</td>
    </tr>
    <tr>
      <th>44</th>
      <td>Madagascar</td>
      <td>2</td>
    </tr>
    <tr>
      <th>45</th>
      <td>Cameroon</td>
      <td>2</td>
    </tr>
    <tr>
      <th>31</th>
      <td>Afghanistan</td>
      <td>2</td>
    </tr>
    <tr>
      <th>47</th>
      <td>Niger</td>
      <td>2</td>
    </tr>
    <tr>
      <th>28</th>
      <td>Sudan</td>
      <td>2</td>
    </tr>
    <tr>
      <th>36</th>
      <td>Uzbekistan</td>
      <td>2</td>
    </tr>
    <tr>
      <th>38</th>
      <td>Angola</td>
      <td>2</td>
    </tr>
    <tr>
      <th>49</th>
      <td>Burkina Faso</td>
      <td>2</td>
    </tr>
    <tr>
      <th>48</th>
      <td>Sri Lanka</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Pakistan</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Nigeria</td>
      <td>2</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Bangladesh</td>
      <td>2</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Ethiopia</td>
      <td>2</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Uganda</td>
      <td>2</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Egypt</td>
      <td>2</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Philippines</td>
      <td>2</td>
    </tr>
    <tr>
      <th>21</th>
      <td>Myanmar</td>
      <td>2</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Kenya</td>
      <td>2</td>
    </tr>
    <tr>
      <th>17</th>
      <td>United Kingdom</td>
      <td>3</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Germany</td>
      <td>3</td>
    </tr>
    <tr>
      <th>33</th>
      <td>Canada</td>
      <td>3</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Italy</td>
      <td>3</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Japan</td>
      <td>3</td>
    </tr>
    <tr>
      <th>46</th>
      <td>Australia</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>United States of America</td>
      <td>3</td>
    </tr>
    <tr>
      <th>18</th>
      <td>France</td>
      <td>3</td>
    </tr>
    <tr>
      <th>24</th>
      <td>Spain</td>
      <td>3</td>
    </tr>
    <tr>
      <th>20</th>
      <td>South Africa</td>
      <td>4</td>
    </tr>
    <tr>
      <th>40</th>
      <td>Mozambique</td>
      <td>4</td>
    </tr>
    <tr>
      <th>42</th>
      <td>Yemen</td>
      <td>4</td>
    </tr>
    <tr>
      <th>30</th>
      <td>Iraq</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div>

Как мы можем заметить, алгоритм выявил следующие кластеры:
* 0 кластер - это кластер развивающихся стран
* 1 кластер - это страны с миллиардным населением
* 2 кластер - это, скорее всего, отстающие страны
* 3 кластер - это развитые страны с хорошей экономикой
* 4 кластер - страны третьего мира, которые осуществляют переход в группу развивающихся стран


## Часть 3. Самоорганизующиеся карты Кохонена.

### Задание 1. Кластеризация банков. 

Просмотрим входящие данные.

```python
banks = pd.read_csv("/content/sample_data/Banks.txt", encoding='Windows 1251', delimiter='\t')
banks.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Номер</th>
      <th>Банк</th>
      <th>Рег. Номер</th>
      <th>Реутеры</th>
      <th>Филиалы</th>
      <th>Город</th>
      <th>Количество рабочих</th>
      <th>Сумма активов</th>
      <th>Собственные активы</th>
      <th>Банковские активы</th>
      <th>Депозиты физ. лиц</th>
      <th>Депозиты Юр. лиц</th>
      <th>Привил. ресурсы</th>
      <th>Ссуда, руб.</th>
      <th>Ссуда, долл.</th>
      <th>Средства в Банке</th>
      <th>Межфилиальные средства</th>
      <th>Бюджет</th>
      <th>Прибыль</th>
      <th>Карты</th>
      <th>Гос. облигации</th>
      <th>Средства ДУ</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>Внешторгбанк</td>
      <td>1000.0</td>
      <td>-</td>
      <td>32</td>
      <td>Москва</td>
      <td>3297</td>
      <td>101660298</td>
      <td>23236327</td>
      <td>84343558</td>
      <td>2086142</td>
      <td>34917304</td>
      <td>18053156</td>
      <td>6588171</td>
      <td>14842031</td>
      <td>30863714</td>
      <td>5919300</td>
      <td>0</td>
      <td>245820</td>
      <td>348793</td>
      <td>749356</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>Газпромбанк</td>
      <td>354.0</td>
      <td>GZPM</td>
      <td>27</td>
      <td>Москва</td>
      <td>2559</td>
      <td>79012789</td>
      <td>9255041</td>
      <td>74409960</td>
      <td>3948269</td>
      <td>35712210</td>
      <td>10154247</td>
      <td>8470823</td>
      <td>31267375</td>
      <td>18833125</td>
      <td>4313630</td>
      <td>0</td>
      <td>355197</td>
      <td>455520</td>
      <td>123111</td>
      <td>8316761</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4</td>
      <td>ООО "Международный Промышленный банк"</td>
      <td>2056.0</td>
      <td>TIBP</td>
      <td>4</td>
      <td>Москва</td>
      <td>459</td>
      <td>77888642</td>
      <td>26409116</td>
      <td>58647197</td>
      <td>157065</td>
      <td>1483061</td>
      <td>25093336</td>
      <td>34043343</td>
      <td>8405719</td>
      <td>6712070</td>
      <td>19195367</td>
      <td>23917</td>
      <td>306196</td>
      <td>3255</td>
      <td>38504</td>
      <td>1662557</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5</td>
      <td>Международный Московский Банк</td>
      <td>1.0</td>
      <td>IMBX</td>
      <td>1</td>
      <td>Москва</td>
      <td>621</td>
      <td>63910966</td>
      <td>1176462</td>
      <td>62436148</td>
      <td>1291941</td>
      <td>42831592</td>
      <td>3600147</td>
      <td>462037</td>
      <td>7797623</td>
      <td>38973392</td>
      <td>830525</td>
      <td>0</td>
      <td>0</td>
      <td>178071</td>
      <td>2033200</td>
      <td>720</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6</td>
      <td>ОАО "АЛЬФА-БАНК"</td>
      <td>1326.0</td>
      <td>ALFM</td>
      <td>17</td>
      <td>Москва</td>
      <td>2323</td>
      <td>57510886</td>
      <td>12446938</td>
      <td>52348562</td>
      <td>4052929</td>
      <td>12574307</td>
      <td>11527973</td>
      <td>4987776</td>
      <td>6077191</td>
      <td>28996950</td>
      <td>5104405</td>
      <td>1594071</td>
      <td>1218928</td>
      <td>1012419</td>
      <td>187085</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

Для построения самоорганизующихся карт Кохонена я установил приложение DeductorStudio.


Запустили Мастер обработки и выберали обработчик Карта Кохонена, указали выходным столбцом поле Прибыль, а поля Филиалы, Сумма активов, Собственные активы, Банковские активы, Средства в банке – входными. 

Карта Кохонена после обучения:

![](https://i.imgur.com/QOsdxXT.png)


Банки первого кластера:
![](https://i.imgur.com/y8Qsp6Q.png)

Банки второго кластера:
![](https://i.imgur.com/iYTZi4K.png)


Банки третьего кластера:
![](https://i.imgur.com/lJ7QDSM.png)


Банки четвёртого кластера:
![](https://i.imgur.com/lARIULK.png)

Как можно заметить, карты Кохонена помогли нам кластеризировать банки. С помощью цветовой диаграммы было определено влияние различных параметров на отношение к тому или иному кластеру. Количество филиалов, например, влияет на кластеризацию слабее, чем банковские активы.